---
title: "STAT 560 Test 1"
author: "Yuchi Hu"
date: "October 6, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=F,warning=F,echo=T,cache=F,fig.height=6,fig.width=10)

```

# 1.
Table B.22 contains data from the Danish Energy Agency on Danish crude oil production. 

## 1)
Plot the data and comment on any features that you observe from the graph. 

## Answer

```{r}
# Load the B.22 data
B.22 <- read.csv('C:\\Users\\George\\Desktop\\TimeSeriesAnalysis\\B.22.csv')

# Crude oil production plot
nrb <- length(B.22$Month)
tt <- 1:nrb

plot(tt, B.22$Oil.Production, type='l', main='Denmark Crude Oil Production', 
     ylab='Crude Oil Production (In Thousands of Tons)', xlab='', xaxt='n')
axis(1, seq(1, nrb, 6), labels=B.22$Month[seq(1, nrb, 6)], las=2)
points(tt, B.22$Oil.Production, pch=16)
```
\begin{center}
Figure 1: Plot of Denmark crude oil production.
\end{center}

**Figure 1** shows the plot of Denmark crude oil production. We can see that crude oil production is more or less a constant process from 2001 to 2003. It briefly exhibits an increasing trend from 2003 to 2005, then exhibits a decreasing trend from 2005 to 2014.

## 2)
Calculate the sample Autocorrelation Function, variogram and Ljung-Box Statistics ($Q_{LB}$). Present your results in a table. 

## Answer

```{r}
# Sample ACF
acf.oil <- acf(B.22$Oil.Production, lag.max=20, plot=F)

# Variogram
G <- NULL
d <- NULL
s.squared <- NULL
variogram.function <- function(y) {
  for (k in 1:20) {
    T <- length(y)
    t <- 1:(T-k)
    
    d[t] <- y[t+k] - y[t]
    d.bar <- (1/(T-k)) * sum(d[t])
    s.squared[k] <- sum((d[t]-d.bar)^2) / (T-k-1)
    G[k] <- s.squared[k] / s.squared[1]
  }
  return(G)
}
vario.oil <- variogram.function(B.22$Oil.Production)

# Ljung-Box statistic
QLB <- NULL
ljung.function <- function(y, acf) {
  T <- length(y)
  for (k in 1:20) {
    QLB[k] <- T * (T+2) * sum((1/(T-1:k)) * (acf$acf[2:(k+1)]^2))
  }
  return(QLB)
}
ljung.oil <- ljung.function(B.22$Oil.Production, acf.oil)

# Create a table
library(knitr)

dt <- cbind(Lag=1:20, 'Sample ACF'=acf.oil$acf[2:21], Variogram=vario.oil, 
            'Ljung-Box Statistic'=ljung.oil)
kable(dt, align='c', caption='Sample ACF, Variogram, and Ljung-Box Statistic for 
      Denmark Crude Oil Production (First 20 Lags)')
```

## 3)
Plot the ACF and variogram. Interpret these graphs.

## Answer

```{r}
par(mfrow=c(1,2))
# ACF plot
acf(B.22$Oil.Production, lag.max=20, main='Sample ACF of Denmark Crude Oil Production')

# Variogram plot
plot(vario.oil, pch=16, main='Variogram of Denmark Crude Oil Production',
     ylab='Variogram', xlab='Lag')
```
\begin{center}
Figure 2: Sample ACF and variogram plots of Denmark crude oil production.
\end{center}

**Figure 2** shows the sample ACF and variogram plots of Denmark crude oil production. We can see that the sample ACF decays very slowly, so the data appears to be nonstationary. The variogram does not converge to a generally stable level, so this is another indication that the data is nonstationary.  

\newpage

## 4)
Plot the first difference of the data and comment on any features that you observe from the graph.

## Answer

```{r}
# First difference of the data
dB.22 <- B.22
dB.22$Oil.Production <- c(NA, diff(dB.22$Oil.Production,1))

# Crude oil production plot (first difference)
plot(tt, dB.22$Oil.Production, type='l', main='Denmark Crude Oil Production, d = 1', 
     ylab='Crude Oil Production (In Thousands of Tons), d = 1', xlab='', xaxt='n')
axis(1, seq(1, nrb, 6), labels=dB.22$Month[seq(1, nrb, 6)], las=2)
points(tt, dB.22$Oil.Production, pch=16)
```
\begin{center}
Figure 3: Plot of Denmark crude oil production, d = 1.
\end{center}

**Figure 3** shows the plot of the first difference of the data. We can see that the data now fluctuates around a constant level: that is, it appears to be stationary.

\newpage

## 5)
Calculate the sample Autocorrelation Function, variogram and Ljung-Box Statistics ($Q_{LB}$) for the differenced data. Present your results in a table.

## Answer

```{r}
diff.oil <- diff(B.22$Oil.Production)

# Sample ACF
acf.diff.oil <- acf(diff.oil, lag.max=20, plot=F)

# Variogram
vario.diff.oil <- variogram.function(diff.oil)

# Ljung-Box statistic
ljung.diff.oil <- ljung.function(diff.oil, acf.diff.oil)

# Create a table
dt <- cbind(Lag=1:20, 'Sample ACF'=acf.diff.oil$acf[2:21], Variogram=vario.diff.oil, 
            'Ljung-Box Statistic'=ljung.diff.oil)
kable(dt, align='c', caption='Sample ACF, Variogram, and Ljung-Box Statistic for 
      Denmark Crude Oil Production (First 20 Lags, d = 1)')
```

## 6)
Plot the sample ACF and variogram for the differenced data. Interpret these graphs.

## Answer

```{r}
par(mfrow=c(1,2))
# ACF plot
acf(diff.oil, lag.max=20, main='Sample ACF of Denmark Crude Oil Production \nd = 1')

# Variogram plot
plot(vario.diff.oil, pch=16, main='Variogram of Denmark Crude Oil Production \nd = 1',
     ylab='Variogram', xlab='Lag')
```
\begin{center}
Figure 4: Sample ACF and variogram plots of Denmark crude oil production, d = 1.
\end{center}

**Figure 4** shows the sample ACF and variogram plots of the first difference of the data. In the ACF plot, there are a couple of autocorrelations that cross the blue dashed lines, which means these autocorrelations are significantly different from 0. But other than that, the ACF fluctuates about 0, and the variogram converges to a generally stable level, indicating a stationary time series.

\newpage

## 7)
What impact did differencing have?

## Answer
Differencing removed the trend in the time series and made it stationary.

# 2.
Table B.25 contains data from the National Highway Traffic Safety Administration on motor vehicle fatalities from 1966 to 2012, along with several other variables. These data are used by a variety of governmental and industry groups, as well as research organizations.

## 1)
Plot the fatalities data. Comment on the graph.

## Answer

```{r}
# Load the B.25 data
B.25 <- read.csv('C:\\Users\\George\\Desktop\\TimeSeriesAnalysis\\B.25.csv')

# Fatalities plot
nrb <- length(B.25$Year)
tt <- 1:nrb

plot(tt, B.25$Fatalities, type='l', main='Motor Vehicle Fatalities', 
     ylab='Fatalities', xlab='Year', xaxt='n')
axis(1, seq(1, nrb, 2), labels=B.25$Year[seq(1, nrb, 2)], las=2)
points(tt, B.25$Fatalities, pch=16)
```
\begin{center}
Figure 5: Plot of motor vehicle fatalities.
\end{center}

**Figure 5** shows the plot of motor vehicle fatalities. We can see that the number of fatalities fluctuates but exhibits an overall decreasing trend.

## 2)
Construct a scatter plot of fatalities versus number of licensed drivers. Comment on the apparent relationship between these two factors.

## Answer

```{r}
# Scatter plot of fatalities vs. number of licensed drivers
plot(B.25$Drivers, B.25$Fatalities, main='Motor Vehicle Fatalities vs. Number of Licensed Drivers',
     ylab='Fatalities', xlab='Licensed Drivers (In Thousands)', pch=16)
```
\begin{center}
Figure 6: Scatter plot of motor vehicle fatalities vs. number of licensed drivers.
\end{center}

**Figure 6** shows the scatter plot of motor vehicle fatalities vs. number of licensed drivers. It appears that the two factors have a negative relationship.

\newpage

## 3)
Fit a simple linear regression model to the fatalities data, using the number of licensed drivers as the predictor variable. Discuss the summary statistics from this model.

## Answer
We fit a simple linear regression model with fatalities as the response and the number of licensed drivers as the predictor. The model summary is below:

```{r}
# Fitted simple linear regression model
model <- lm(Fatalities ~ Drivers, data=B.25)
# Model summary
summary(model)
```
```{r}
# Model coefficients
model$coefficients
```
```{r}
# Model AIC
AIC(model)
```

Using the estimated coefficients, the fitted simple linear regression model is
$$\hat{y} = 67921.778 - 0.144x$$
where $\hat{y}$ = predicted value of fatalities and $x$ = number of licensed drivers.

We can see that the coefficient for drivers is significant (p-value = 5.91e-15) at an alpha level of 0.05. The AIC of the model is 884.8693. The multiple and adjusted R^2^ are 0.7452 and 0.7396 respectively, so the model explains about 74% of the variability in fatalities.

## 4)
Analyze the residuals from the model in part 3). Discuss the adequacy of the fitted model. (Limit the pages to 4)

## Answer
### Residual Plots and Normality Test
To analyze the residuals and check the adequacy of the model, we can look at the residual plots of the model.

```{r}
par(mfrow=c(2,2), oma=c(0,0,0,0))
# Residual plots
qqnorm(model$res, datax=TRUE, pch=16, 
       xlab='Residual', main='Normal Q-Q Plot of the Residuals')
qqline(model$res, datax=TRUE)
plot(model$fit, model$res, pch=16, xlab='Fitted Value', ylab='Residual', 
     main='Residuals vs. Fitted Values') ; abline(h=0)
hist(model$res, col='gray', xlab='Residual', main='Histogram of the Residuals')
plot(model$res, type='l', xlab='Observation Order', ylab='Residual', 
     main='Residuals vs. Order of the Data')
points(model$res, pch=16, cex=0.8) ; abline(h=0)
```
\begin{center}
Figure 7: Residual plots for the fatalities model.
\end{center}

\newpage

**Figure 7** contains the residual plots for the fatalities model. The normal q-q plot of the residuals shows that most of the residuals follow a normal distribution except at the tails. The histogram of the residuals does not look normal. The residuals vs. fitted values plot indicates nonconstant variance. The residuals vs. order of the data plot indicates that the residuals are positively autocorrelated. 

We can also use the Shapiro-Wilk test to test the normality of the residuals.

```{r}
# Shapiro-Wilk test
shapiro.test(model$res)
```

The null hypothesis is that the residuals are normally distributed. Since the p-value of 0.03413 is less than an alpha level of 0.05, we reject the null hypothesis and conclude that the residuals are not normally distributed.

### Prediction R^2^
To get an idea for how well the model will predict new data, we can calculate the prediction R^2^
$$R^2_{Prediction}=1-\frac{PRESS}{SS_{T}}$$
where PRESS = prediction error sum of squares and $SS_{T}$ = total sum of squares.

The prediction R^2^ for the fatalities model is:

```{r}
# Prediction R-squared
anova <- anova(model)
SST <- sum(anova$`Sum Sq`)
PRESS <- sum(rstandard(model, type='pred')^2)
1 - PRESS/SST
```

Thus, this model accounts for about 72% of the variability in new data, which is pretty good.

### Studentized Residuals, Hat Diagonals, and Cook's Distance
In addition to residual plots, we can examine the studentized residuals, hat diagonals, and Cook's distance.

```{r}
# Vectors of residuals and other diagnostics
a <- round(residuals(model), 5)
b <- round(rstandard(model), 5)
c <- round(rstudent(model), 5)
d <- round(hatvalues(model), 5)
e <- round(cooks.distance(model), 5)

# Combine above vectors into a table
table <- cbind(Year=1966:2012, Residuals=a, 'Studentized Residuals'=b,
               'R-Student'=c, 'h[i,i]'=d, "Cook's Distance"=e)
kable(table, align='c',
      caption='Residuals and Other Diagnostics for the Fatalities Model')
```

**Table 3** contains the studentized residuals, hat diagonals, and Cook's distance for the fatalities model.

Absolute values of the studentized residuals that are greater than three or four indicate potential unusual values or outliers. The largest studentized residual is -1.82218 (observation from 2011); similarly, the largest R-student is -1.87221 (observation from 2011). So there does not appear to be any unusual values or outliers. 

Hat diagonals that are greater than twice their average value 2*p*/*n* (*p* = number of parameters and *n* = number of observations) indicate high-leverage observations. There are *p* = 2 parameters in the fatalities model and *n* = 47 observations, so 2*p*/*n* = 2(2)/47 = 0.0851. Hat diagonals that exceed 0.0851 correspond to the first three observations in the data. However, hat diagonals will identify points that are potentially influential due to their location in the predictor variable space (observations with extreme predictor values are high leverage). We want to consider both the location of the point and the response variable in measuring influence. This can be accomplished by examining Cook's distance.

Observations with Cook's distance greater than one are considered influential. The largest Cook's distance is 0.1209 (observation from 2011), so there does not appear to be any influential observations.

### Conclusion
Since we found that the residuals are not normally distributed, have nonconstant variance, and are positively autocorrelated, the fitted model is not adequate.

## 5)
Calculate the Durbin-Watson test statistic for the model in part 3). Is there evidence of autocorrelation in the residuals? Is a time series regression model more appropriate than an OLS model for these data?

## Answer
We will use the "dwt" function from the **car** package to calculate the Durbin-Watson test statistic for the model. We will test for positive autocorrelation with a one-sided test.

```{r}
# Durbin-Watson test
library(car)
dwt(model, alternative='positive')
```

The Durbin-Watson test statistic is 0.518. The null hypothesis is that the errors are uncorrelated. Since the p-value is extremely small, we reject the null hypothesis and conclude that the errors are positively autocorrelated. Thus, a time series regression model is more appropriate than an OLS model for these data.

\newpage

## 6)
There are several candidate predictors that could be added to the model. Use stepwise regression to find an appropriate model.

## Answer
We perform stepwise "mixed" selection with fatalities as the response and resident population, number of licensed drivers, number of registered motor vehicles, vehicle miles traveled, and annual unemployment rate as the predictors.

```{r}
# Fitted full model
model.full <- lm(Fatalities ~ Population + Drivers + Vehicles + Miles.Traveled + 
                   Unemployment.Rate, data=B.25)
# Stepwise selection
step.both <- step(model.full, direction='both')
```

The stepwise "mixed" selection is a combination of forward selection and backward elimination. It removes or adds the predictor that decreases AIC the most until no predictors remain that can be removed or added to decrease AIC. As we can see, stepwise selection sequentially removed vehicle miles traveled (*Miles.Traveled*), number of licensed drivers (*Drivers*), and number of registered motor vehicles (*Vehicles*). Thus, the best model contains resident population (*Population*) and annual unemployment rate (*Unemployment.Rate*). 

The summary of this new model is below:

```{r}
# Fitted new model
model2 <- lm(Fatalities ~ Population + Unemployment.Rate, data=B.25)
# Model summary
summary(model2)
```
```{r}
# Model coefficients
model2$coefficients
```
```{r}
# Model AIC
AIC(model2)
```

Using the estimated coefficients, the new fitted multiple linear regression model is
$$\hat{y} = 82594.610 - 0.125x_1 - 1095.279x_2$$
where $\hat{y}$ = predicted value of fatalities, $x_1$ = resident population, and $x_2$ = annual unemployment rate.

We can see that the coefficients for both predictors are significant at an alpha level of 0.05. The AIC of the model is 866.2024, which is smaller than that of the original model (884.8693). The adjusted R^2^ is 0.8284, which is greater than that of the original model (0.7396). Thus, the new model is a better fit than the original model.

## 7)
Calculate the Durbin-Watson test statistic for the model in part 6). Is there evidence of autocorrelation in the residuals? Is a time series regression model more appropriate than an OLS model for these data?

## Answer
We will use the "dwt" function from the **car** package to calculate the Durbin-Watson test statistic for the model. We will test for positive autocorrelation with a one-sided test.

```{r}
# Durbin-Watson test
dwt(model2, alternative='positive')
```

The Durbin-Watson test statistic is 0.569. The null hypothesis is that the errors are uncorrelated. Since the p-value is extremely small, we reject the null hypothesis and conclude that the errors are positively autocorrelated. Thus, a time series regression model is more appropriate than an OLS model for these data (Cochrane-Orcutt method is applied in part 8).

## 8)
Analyze the residuals from the model that you obtained in part 6). Discuss the adequacy of the fitted model. (Limit the pages to 4)

## Answer
### Residual Plots and Normality Test
To analyze the residuals and check the adequacy of the new model, we can look at the residual plots of the model.

```{r}
par(mfrow=c(2,2), oma=c(0,0,0,0))
# Residual plots
qqnorm(model2$res, datax=TRUE, pch=16, 
       xlab='Residual', main='Normal Q-Q Plot of the Residuals')
qqline(model2$res, datax=TRUE)
plot(model2$fit, model2$res, pch=16, xlab='Fitted Value', ylab='Residual', 
     main='Residuals vs. Fitted Values') ; abline(h=0)
hist(model2$res, col='gray', xlab='Residual', main='Histogram of the Residuals')
plot(model2$res, type='l', xlab='Observation Order', ylab='Residual', 
     main='Residuals vs. Order of the Data')
points(model2$res, pch=16, cex=0.8) ; abline(h=0)
```
\begin{center}
Figure 8: Residual plots for the new fatalities model.
\end{center}

**Figure 8** contains the residual plots for the new fatalities model. The normal q-q plot of the residuals shows that most of the residuals follow a normal distribution except at the tails. The histogram of the residuals looks mostly normal as well. The residuals vs. fitted values plot does not show any obvious patterns in the residuals, so the equal variance assumption does not appear to be violated. The residuals vs. order of the data plot indicates that the residuals are positively autocorrelated.

We can also use the Shapiro-Wilk test to test the normality of the residuals.

```{r}
# Shapiro-Wilk test
shapiro.test(model2$res)
```

The null hypothesis is that the residuals are normally distributed. Since the p-value of 0.27 is greater than an alpha level of 0.05, we fail to reject the null hypothesis and conclude that there is insufficient evidence that the residuals are not normally distributed.

### Prediction R^2^
To get an idea for how well the model will predict new data, we can calculate the prediction R^2^
$$R^2_{Prediction}=1-\frac{PRESS}{SS_{T}}$$
where PRESS = prediction error sum of squares and $SS_{T}$ = total sum of squares.

The prediction R^2^ for the new fatalities model is:

```{r}
# Prediction R-squared
anova <- anova(model2)
SST <- sum(anova$`Sum Sq`)
PRESS <- sum(rstandard(model2, type='pred')^2)
1 - PRESS/SST
```

Thus, this model accounts for about 81.6% of the variability in new data, which is pretty good.

### Studentized Residuals, Hat Diagonals, and Cook's Distance
In addition to residual plots, we can examine the studentized residuals, hat diagonals, and Cook's distance.

```{r}
# Vectors of residuals and other diagnostics
a <- round(residuals(model2), 5)
b <- round(rstandard(model2), 5)
c <- round(rstudent(model2), 5)
d <- round(hatvalues(model2), 5)
e <- round(cooks.distance(model2), 5)

# Combine above vectors into a table
table <- cbind(Year=1966:2012, Residuals=a, 'Studentized Residuals'=b,
               'R-Student'=c, 'h[i,i]'=d, "Cook's Distance"=e)
kable(table, align='c',
      caption='Residuals and Other Diagnostics for the New Fatalities Model')
```

**Table 4** contains the studentized residuals, hat diagonals, and Cook's distance for the new fatalities model.

Absolute values of the studentized residuals that are greater than three or four indicate potential unusual values or outliers. The largest studentized residual is 2.04203 (observation from 1980); similarly, the largest R-student is 2.12173 (observation from 1980). So there does not appear to be any unusual values or outliers. 

Hat diagonals that are greater than twice their average value 2*p*/*n* (*p* = number of parameters and *n* = number of observations) indicate high-leverage observations. There are *p* = 3 parameters in the new fatalities model and *n* = 47 observations, so 2*p*/*n* = 2(3)/47 = 0.1277. There are four observations with hat diagonals that exceed 0.1277. However, hat diagonals will identify points that are potentially influential due to their location in the predictor variable space (observations with extreme predictor values are high leverage). We want to consider both the location of the point and the response variable in measuring influence. This can be accomplished by examining Cook's distance.

Observations with Cook's distance greater than one are considered influential. The largest Cook's distance is 0.072 (observation from 1966), so there does not appear to be any influential observations.

### Conclusion
Since we found that the residuals are positively autocorrelated, the fitted model is not adequate.

### Cochrane-Orcutt Method
The autocorrelation problem may be fixed by applying the Cochrane-Orcutt method, which will adjust (transform) the parameter estimates and their standard errors. The model summary is below:

```{r}
# Cochrane-Orcutt method
library(orcutt)
model2.cochrane <- cochrane.orcutt(model2)
summary(model2.cochrane)
```
```{r}
# Model coefficients
model2.cochrane$coefficients
```

We can see that the Durbin Watson statistic for the transformed model is 1.67701. Since the p-value is 0.09142 > 0.05, we fail to reject the null hypothesis and conclude that there is insufficient evidence of autocorrelation in the errors.

Using the estimated coefficients from the model summary, the fitted time series regression model is
$$\hat{y_{t}}' =  85961.916 - 0.135x_{1,t}' - 1170.155x_{2,t}'$$
where $\hat{y_{t}}'$ = predicted value of fatalities (transformed) at time $t$, $x_{1,t}'$ = resident population (transformed) at time $t$, and $x_{2,t}'$ = annual unemployment rate (transformed) at time $t$.
