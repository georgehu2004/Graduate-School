---
title: "Increasing Profits Through Good Customers"
subtitle: "STAT 551 Final Project"
author: "Yuchi Hu"
date: "April 21, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=F,warning=F,echo=F,fig.height=4,fig.width=6,cache=F,out.extra='',fig.pos='h')
```

```{r, eval=F}
# Install packages used in this project
if(!require(readxl)){install.packages("readxl")}
if(!require(dplyr)){install.packages("dplyr")}
if(!require(earth)){install.packages("earth")}
if(!require(ggplot2)){install.packages("ggplot2")}
if(!require(gridExtra)){install.packages("gridExtra")}
if(!require(caret)){install.packages("caret")}
if(!require(ROCit)){install.packages("ROCit")}
if(!require(ggmosaic)){install.packages("ggmosaic")}
if(!require(knitr)){install.packages("knitr")}
if(!require(reshape2)){install.packages("reshape2")}
if(!require(grid)){install.packages("grid")}
if(!require(Rprofet)){install.packages("Rprofet")}
if(!require(MASS)){install.packages("MASS")}
```

```{r}
# Load packages used in this project
library(readxl)
library(dplyr)
library(earth)
library(ggplot2)
library(gridExtra)
library(caret)
library(ROCit)
library(ggmosaic)
library(knitr)
library(reshape2)
library(grid)
library(Rprofet)
library(MASS)
```

\tableofcontents 
\newpage

# 1. Introduction
The data for this project comes from RetentionDataRaw.xlsx, which we have already used extensively in the Midterm. The data is composed of credit card monthly billing statements from February 2010 to November 2010 (shorter time frames for closed accounts). The task now is to focus on the profitable or good customers. We want to give incentives to these customers in the form of, say, credit line increases or annual fee waivers to encourage them to use their credit cards more, thereby increasing our profit. Before we can do any modeling, we need to create the "model dataset" from the retention data. We will use the model dataset to build and evaluate two models: logistic regression and multivariate adaptive regression splines (MARS). We then compare these models' performances to that of the *Good Customer Score*. Lastly, we calculate profitability in the models' gains tables.

# 2. Creating the Model Dataset
The retention data originally has 97,465 rows and 26 columns. After removing the rows with missing ID's, we are left with 91,502 rows representing 9,997 customers. We should note that when we refer to the number of customers, we are really referring to the number of unique ID's since a customer could have multiple ID's if they have multiple accounts.

As the first step in creating the model dataset, we need to remove customers that we deem to be too risky. We also need to define "good" and "bad" customers.  

```{r}
# Load the data
path <- 'C:/Users/George/Desktop/PredictiveAnalyticsI/Midterm/RetentionDataRaw.xlsx'
x <- as.data.frame(read_excel(path, sheet='Cycle Data'))
# Replace spaces in column names with periods
names(x) <- make.names(names(x), unique=TRUE)
```

```{r}
# Convert DebtDimID to factor
x$DebtDimID <- as.factor(x$DebtDimId)
# Drop the original DebtDimID column
x[1] <- NULL
# Drop NA rows
x <- x[!is.na(x$DebtDimID), ]
# Number of unique ID's in this data = 9,997
#cat("Number of unique ID's:", length(unique(x$DebtDimID)))
```

```{r}
# Change blank External Status to O (open)
x[is.na(x$External.Status), ]$External.Status <- 'O'
# Convert External Status and ClosureReason to factors
x$External.Status <- as.factor(x$External.Status)
x$ClosureReason <- as.factor(x$ClosureReason)
# Convert Good Customer Score to numeric
x$Good.Customer.Score <- as.numeric(x$Good.Customer.Score)
# Drop Behavior Score, Quarterly FICO Score
x$Behavior.Score <- NULL
x$Quarterly.Fico.Score <- NULL
```

## 2.1 Remove Risky Customers
We found out from the Midterm that some customers are too risky to give more money to, so we will simply remove them from the data. The customer is deemed too risky if their *Row Num* = 1 (month 1) satisfies any of the following conditions:  

- *Days Deliq* > 0 (more than 0 days delinquent)
- non-blank *External Status* (a blank *External Status* corresponds to an open account)
- *Opening Balance* > *Credit Limit*
- *Ending Balance* > *Credit Limit*

We find that 4,167 of the 9,997 customers are too risky, so we are left with 5,830 customers after removing the risky customers. Overall, we are left with 55,895 rows of data.

```{r}
# Remove risky customers (Days Deliq > 0 or non-blank External Status...
# ...or Opening/Ending Balance > Credit Limit in Row Num = 1)
removed.customers <- subset(x[x$Row.Num == 1,], Days.Deliq > 0 | External.Status != 'O' | Opening.Balance > Credit.Limit |
                              Ending.Balance > Credit.Limit)

# Remove duplicate rows
removed.customers <- removed.customers[!duplicated(removed.customers$DebtDimID), ]

# Number of unique ID's of risky customers = 4167
#cat("Number of unique ID's of risky customers:", length(unique(removed.customers$DebtDimID)))
```

```{r}
# Data after removing risky customers
x <- x[!x$DebtDimID %in% removed.customers$DebtDimID, ]

# Number of unique ID's after removing risky customers = 5830
#cat("Number of unique ID's after removing risky customers:", length(unique(x$DebtDimID)))
```

## 2.2 Define Good and Bad Customers 
Next, for the remaining customers, we create *Bad* (the outcome variable) to define whether they are good (*Bad*=0) or bad (*Bad*=1) customers. A customer is defined as bad if they satisfy any of the following conditions:

- *Days Deliq* $\ge$ 90 (90 or more days delinquent) in the final month
- *External Status* other than blank (open account) or "C" (closed account) in month 7 or later

We find that 610 customers satisfy the first criterion and 669 customers satisfy the second. (There are some customers who satisfy both criteria.) Customers who do not satisfy any of the two criteria are defined as good.

```{r}
# Extract final month of each customer
tmp <- x %>%
  group_by(DebtDimID) %>%
  arrange(Row.Num) %>%
  filter(row_number()==n())

# 90 or more days delinquent in final month
tmp <- tmp[tmp$Days.Deliq >= 90, ]

# Number of unique ID's of customers who are 90 or more days delinquent in final month = 610
#cat("Number of unique ID's of customers who are 90 or more days delinquent in final month:", length(unique(tmp$DebtDimID)))

# Bad = 1 if 90 or more days delinquent in final month 
x$Bad <- as.factor(ifelse(x$DebtDimID %in% tmp$DebtDimID, 1, 0))
```

```{r}
# External Status other than blank or 'C' in month 7 or later
tmp <- subset(x[x$Row.Num >= 7, ], External.Status != 'O' & External.Status != 'C')

# Number of unique ID's of customers with External Status other than blank or 'C' in month 7 or later = 669
#cat("Number of unique ID's of customers with External Status other than blank or 'C' in month 7 or later:", length(unique(tmp$DebtDimID)))

# Bad = 1 if External Status is not blank or 'C' in month 7 or later
x[x$DebtDimID %in% tmp$DebtDimID, ]$Bad <- 1
```

## 2.3 Keep Only *Row Num* = 1 for Each Customer
After removing the risky customers and defining *Bad* for the remaining customers, the next step in the creation of the model dataset is to keep only *Row Num* = 1 (month 1) for each customer. Interestingly, the customer with ID=1695646 has a duplicate row, which we remove. The final number of rows for the model dataset is 5,825, with one row per customer.

```{r}
# Model dataset (Row Num = 1 observations)
model.data <- x[x$Row.Num == 1, ]

# Remove duplicate rows
model.data <- model.data[!duplicated(model.data$DebtDimID), ]

# Create data frame with Bad and Good Customer Score for comparison purposes later
gcs.data <- model.data[, c('Bad', 'Good.Customer.Score')]

# Number of unique ID's in the model dataset = 5825
#cat("Number of unique ID's in the model dataset: ", length(unique(model.data$DebtDimID)))
```

## 2.4 Input Variables
We can remove the following variables from the model dataset:

- *Row Num* -- this is 1 for every customer
- *External Status* -- this is blank (open account) for every customer
- *Days Deliq* and *Over limit Amount* -- these are 0 for every customer
- *Good Customer Score*, *Behavior Score* and *Quarterly Fico Score* -- these are specifically prohibited from the analysis
- *ClosureReason* -- we will create a variable to deal with the 36 factor levels (see below)
- *Open Date*, *Last Statement Date*, *Cycle Date*, *Month End Date*, and *Last Payment Date* -- these are dates

```{r}
# Remove Row Num, Days Deliq, Over limit Amount, and Good Customer Score
model.data[, c('Row.Num', 'External.Status', 'Days.Deliq', 'Over.limit.Amount', 'Good.Customer.Score')] <- NULL
# Remove Open Date, Last Statement Date, Cycle Date, Month End Date, and Last Payment Date
model.data[, c('Open.Date', 'Last.Statement.Date', 'Cycle.Date', 'Month.End.Date', 'Last.Payment.Date')] <- NULL
```

The remaining input variables are:

- *Months On Book*
- *Credit Limit*
- *Opening Balance*
- *Ending Balance*
- *Actual Min Pay Due*
- *Total Min Pay Due*
- *Net Payments During Cycle* 
- *Net Purchases During Cycle*
- *Net Cash Advances During Cycle*
- *Net Premier Fees Billed During Cycle*
- *Net Behavior Fees Billed During Cycle*
- *Net Concessions Billed During Cycle*

In addition, we create the following input variables:

- *Opening Utilization* = *Opening Balance* / *Credit Limit*
- *Ending Utilization* = *Ending Balance* / *Credit Limit*
- *Utilization Difference* = *Ending Utilization* - *Opening Utilization*
- *Total Fees and Concessions* = *Net Premier Fees Billed During Cycle* + *Net Behavior Fees Billed During Cycle* - *Net Concessions Billed During Cycle*
- *Payment Type* = index of whether a customer paid above, below, or exactly their total minimum payment due or if they made no payment
- *Closure Reason Given* = index of whether or not a closure reason was given

```{r}
#### Created variables
# Opening Utilization = Opening Balance / Credit Limit
model.data$Opening.Utilization <- model.data$Opening.Balance / model.data$Credit.Limit
# Ending Utilization = Ending Balance / Credit Limit
model.data$Ending.Utilization <- model.data$Ending.Balance / model.data$Credit.Limit
# Utilization Difference = Ending Utilization - Opening Utilization 
model.data$Utilization.Difference <- model.data$Ending.Utilization - model.data$Opening.Utilization
# Total Fees and Concessions = Net Premier Fees Billed During Cycle + Net Behavior Fees Billed During Cycle - Net Concessions Billed During Cycle
model.data$Total.Fees.and.Concessions <- model.data$Net.Premier.Fees.Billed.During.Cycle + model.data$Net.Behavior.Fees.Billed.During.Cycle -
  model.data$Net.Concessions.Billed.During.Cycle
# Payment Type
for (i in 1:nrow(model.data)){
  if (model.data$Net.Payments.During.Cycle[i] > model.data$Total.Min.Pay.Due[i]){
    model.data$Payment.Type[i] <- 'Above'
  }
  else if (model.data$Net.Payments.During.Cycle[i] == model.data$Total.Min.Pay.Due[i]){
    model.data$Payment.Type[i] <- 'Exact'
  }
  else if (model.data$Net.Payments.During.Cycle[i] == 0){
    model.data$Payment.Type[i] <- 'No Payment'
  }
  else {
    model.data$Payment.Type[i] <- 'Below'
  }
}
model.data$Payment.Type <- as.factor(model.data$Payment.Type)
# Closure Reason Given 
model.data$Closure.Reason.Given <- as.factor(ifelse(model.data$ClosureReason == 'NULL', 0, 1))
# Remove ClosureReason
model.data[, 'ClosureReason'] <- NULL
```

\newpage

# 3. Exploratory Data Analysis on the Model Dataset
Now that we have created the model dataset, we can perform exploratory data analysis on it. The model dataset is composed of 5,825 rows (number of customers) and 20 columns (18 inputs + outcome variable + ID). 

## 3.1 Bar Charts and Histograms
First, let's look at the distributions of the levels of the categorical variables.

```{r, fig.height=4, fig.width=10}
#### Bar charts of categorical variables 
theme_update(plot.title=element_text(hjust=0.5))
# Bad
p1 <- ggplot(data=model.data, aes(x=Bad, fill=Bad)) + geom_bar() + geom_text(stat='count', aes(label=..count..), vjust=-0.05) +
  scale_fill_manual(values=c("#E69F00", "#56B4E9")) + theme(legend.position='none')
# Payment Type
p2 <- ggplot(data=model.data, aes(x=Payment.Type, fill=Bad)) + geom_bar(position=position_dodge()) + 
  geom_text(stat='count', aes(label=..count..), position = position_dodge(0.9), vjust=0) + 
  theme(axis.text.x=element_text(angle=45, hjust=1)) + 
  scale_fill_manual(values=c("#E69F00", "#56B4E9")) 
# Closure Reason Given
p3 <- ggplot(data=model.data, aes(x=Closure.Reason.Given, fill=Bad)) + geom_bar(position=position_dodge()) + 
  geom_text(stat='count', aes(label=..count..), position = position_dodge(0.9), vjust=0) + 
  scale_fill_manual(values=c("#E69F00", "#56B4E9")) 

grid.arrange(p1, p2, p3, ncol=3, top=textGrob('Bar Charts of Categorical Variables'))
```
\begin{center}
Figure 1: Bar charts of the categorical variables (good=orange, bad=blue).
\end{center}

From **Figure 1**, we see that there are 5,072 (87%) good customers and 753 (13%) bad customers. In terms of *Payment Type*, we see that most customers either paid above or exactly their total minimum payment due, which is good since this is an indication that they are good customers. In terms of *Closure Reason Given*, 19 customers have a reason listed for their account closure, which is odd since all of the customers left in the model dataset have a blank *External Status* or open account. This tells us that perhaps these 19 accounts should've been marked as closed (*External Status* of "C").

```{r, fig.height=10, fig.width=15}
# Select only the numeric variables
nums <- unlist(lapply(model.data, is.numeric))

# Histograms of numeric variables
plots <- list() 
for(i in names(model.data[, nums])){
  plots[[i]] <- ggplot(model.data, aes_string(x=i, fill='Bad')) + 
    geom_histogram(alpha=0.7, position='identity') + scale_fill_manual(values=c("#E69F00", "#56B4E9")) +
    labs(x=i) + theme(legend.position='none') 
}

grid.arrange(grobs=plots, ncol=4, top=textGrob('Histograms of Numeric Variables', gp=gpar(fontsize=15)))
```
\begin{center}
Figure 2: Histograms of the numeric variables grouped by Bad (good=orange, bad=blue).
\end{center}

**Figure 2** shows the histograms of the numeric variables grouped by *Bad*. We see that good and bad customers have similar distributions for each numeric variable.  

\newpage

## 3.2 Correlation Matrix
**Figure 3** shows the correlation matrix of the numeric variables in the model dataset. We see that many of the variables are correlated. 

```{r, fig.height=7, fig.width=11}
# Correlation matrix
correlation.mat <- round(cor(model.data[, nums]), 2)

# Upper triangle of the correlation matrix
get_upper_tri <- function(cormat){
  cormat[lower.tri(cormat)] <- NA
  return(cormat)
}

# Get upper triangle of the correlation matrix
upper_tri <- get_upper_tri(correlation.mat)
correlation.mat.long <- melt(upper_tri, na.rm=TRUE)
# Correlation matrix heatmap
ggplot(data = correlation.mat.long, aes(Var2, Var1, fill=value)) + geom_tile(color='white') + 
  scale_fill_gradient2(low='#0072B2', high='#D55E00', mid ='white', midpoint=0, limit=c(-1,1), space='Lab',
                       name='Pearson\nCorrelation') +
  theme_minimal() + theme(axis.text.x=element_text(angle=45, vjust=1, hjust=1), plot.title=element_text(size=16, hjust=0.5)) + 
  coord_fixed() + labs(title='Correlation Matrix of Numeric Variables', x='', y='')
```
\begin{center}
Figure 3: Correlation matrix of the numeric variables.
\end{center}

## 3.3 Binning
Using **BinProfet()** from the **Rprofet** package, we bin four variables: *Total Min Pay Due*, *Net Payments*, *Net Purchases*, and *Net Premier Fees*. We choose these variables since they appear to contain outliers, whose effect we want to minimize. These binned variables will replace their original counterparts as inputs for the models. The bar charts of the four binned variables are shown in **Figure 4**. 

```{r}
# Bin Total Min Pay Due, Net Payments, Net Purchases, and Net Premier Fees
binned.data <- BinProfet(model.data, id="DebtDimID", target="Bad", 
                         varcol=c("Total.Min.Pay.Due", "Net.Payments.During.Cycle", "Net.Purchases.During.Cycle",
                                  "Net.Premier.Fees.Billed.During.Cycle"), num.bins=10)
# Add binned variables to model dataset
model.data$binned.total.min.pay.due <- binned.data$Total.Min.Pay.Due_Bins
model.data$binned.net.payments <- binned.data$Net.Payments.During.Cycle_Bins
model.data$binned.net.purchases <- binned.data$Net.Purchases.During.Cycle_Bins
model.data$binned.net.premier.fees <- binned.data$Net.Premier.Fees.Billed.During.Cycle_Bins
```

```{r, fig.height=7, fig.width=9}
#### Bar charts of binned variables 
# Total Min Pay Due
p1 <- ggplot(data=model.data, aes(x=binned.total.min.pay.due)) + geom_bar() + geom_text(stat='count', aes(label=..count..), vjust=-0.05) +
  labs(x='Total Min Pay Due (Binned)') + theme(axis.text.x=element_text(angle=45, hjust=1))
# Net Payments
p2 <- ggplot(data=model.data, aes(x=binned.net.payments)) + geom_bar() + geom_text(stat='count', aes(label=..count..), vjust=-0.05) +
  labs(x='Net Payments (Binned)') + theme(axis.text.x=element_text(angle=45, hjust=1))
# Net Purchases
p3 <- ggplot(data=model.data, aes(x=binned.net.purchases)) + geom_bar() + geom_text(stat='count', aes(label=..count..), vjust=-0.05) +
  labs(x='Net Purchases (Binned)') + theme(axis.text.x=element_text(angle=45, hjust=1))
# Net Premier Fees
p4 <- ggplot(data=model.data, aes(x=binned.net.premier.fees)) + geom_bar() + geom_text(stat='count', aes(label=..count..), vjust=-0.05) +
  labs(x='Net Premier Fees (Binned)') + theme(axis.text.x=element_text(angle=45, hjust=1))

grid.arrange(p1, p2, p3, p4, ncol=2, top=textGrob('Bar Charts of Binned Variables'))
```
\begin{center}
Figure 4: Bar charts of the binned Total Min Pay Due, Net Payments, Net Purchases, and Net Premier Fees.
\end{center}

# 4. The Models
Before building the models, we use **createDataPartition()** from the **caret** package to split the model dataset into training (70%; 4,079 observations) and validation sets (30%; 1,746 observations). This function partitions the data while maintaining the class ratios (stratified sampling).

```{r}
set.seed(1)
# Split the gcs dataset 70:30 into training and validation sets (stratified sampling)
sample <- createDataPartition(model.data$Bad, p=0.7, list=F)
train <- model.data[sample,]
test <- model.data[-sample,]
```

```{r}
# Vector of input names
predictors <- names(model.data[,-c(6, 7, 8, 10, 13, 14)])
# Construct model formula
formula <- formula(paste("Bad ~ ", paste(predictors, collapse=" + ")))
```

## 4.1 Logistic Regression
We build a logistic regression model with *Bad* as the outcome and the 18 variables mentioned in **Section 2.4** as the inputs (remember that the four binned variables replace their original counterparts). We perform stepwise variable selection using **StepAIC** from the **MASS** package. The summary of the final logistic regression model is below:

```{r}
# Logistic regression model
model.logistic <- glm(formula, data=train, family=binomial)

# Perform stepwise variable selection
#step.model <- model.logistic %>% stepAIC(trace=FALSE)
#coef(step.model)

# Stepwise logistic regression model 
model.logistic <- glm(Bad ~ Months.On.Book + Credit.Limit + Opening.Balance + Net.Concessions.Billed.During.Cycle + Opening.Utilization + 
                        Ending.Utilization + Payment.Type + binned.total.min.pay.due, data=train, family=binomial)
# Summary
summary(model.logistic)

# AIC
aic.logistic <- round(AIC(model.logistic), 3)
# Predicted probabilities of Bad 
probs.logistic <- predict(model.logistic, newdata=test, type='response')
```

We see that there are 8 inputs in the final model compared to the 18 in the original model. The AIC of the final model is 2973.4.

Next, we move on to model evaluation (KS, ROC, gains table, and lift).

```{r, fig.height=4, fig.width=9}
#### ROC and KS (logistic)
# ROC
roc.logistic.train <- rocit(score=model.logistic$fitted.values, class=train$Bad, negref=0)  # Training
roc.logistic.test <- rocit(score=probs.logistic, class=test$Bad, negref=0)  # Validation

# AUC
auc.logistic.train <- round(roc.logistic.train$AUC, 4)  # Training
auc.logistic.test <- round(roc.logistic.test$AUC, 4)  # Validation

par(mfrow=c(1,2))
# KS plots
ksplot.logistic.train <- ksplot(roc.logistic.train)  # Training
ksplot.logistic.test <- ksplot(roc.logistic.test)  # Validation

# KS statistics
ks.logistic.train <- round(ksplot.logistic.train$`KS stat`, 4)  # Training
ks.logistic.test <- round(ksplot.logistic.test$`KS stat`, 4)  # Validation
```
\begin{center}
Figure 5: KS plots of the training (left) and validation sets (right) for logistic regression.
\end{center}

**Figure 5** shows the KS plots of the training and validation sets for logistic regression.

```{r}
#### ROC and KS (logistic)
# ROC curves
plot(roc.logistic.train, col=c(1,'gray50'), legend=FALSE, YIndex=FALSE)
lines(roc.logistic.test$TPR~roc.logistic.test$FPR, col='#D55E00', lwd=2)
legend('bottomright', col=c(1,'#D55E00'), c(paste0('Training: AUC = ', auc.logistic.train, ', KS = ', ks.logistic.train), 
                                            paste0('Validation: AUC = ', auc.logistic.test, ', KS = ', ks.logistic.test)), lwd=2)
title(main='Logistic ROC Curves')
```
\begin{center}
Figure 6: ROC curves of the training and validation sets for logistic regression.
\end{center}

**Figure 6** shows the ROC curves of the training and validation sets for logistic regression. The training and validation AUC's are 0.695 and 0.683, respectively. The training and validation KS statistics are 0.310 and 0.276, respectively.

```{r, fig.height=5, fig.width=10}
#### Gains table (logistic)
# Gains table
gtable.logistic.training <- gainstable(score=model.logistic$fitted.values, class=train$Bad, negref=0, ngroup=10)  # Training
#kable(as.data.frame(gtable.logistic.training[1:11]), digits=2, caption='Gains Table (Training)')
gtable.logistic.test <- gainstable(score=probs.logistic, class=test$Bad, negref=0, ngroup=10)  # Validation
kable(as.data.frame(gtable.logistic.test[1:11]), digits=2, caption='Logistic Gains Table (Validation)')

par(mfrow=c(1,2))
# Lift
plot(gtable.logistic.training)  # Training
title('Logistic Lift (Training)')
plot(gtable.logistic.test)  # Validation
title('Logistic Lift (Validation)')
```
\begin{center}
Figure 7: Lift and cumulative lift of training (left) and validation sets (right) for logistic regression.
\end{center}

**Table 1** shows the gains table of the validation set, and **Figure 7** shows the lift and cumulative lift of the training and validation sets for logistic regression.

## 4.2 MARS
We build a MARS model with *Bad* as the outcome and the 18 variables mentioned in **Section 2.4** as the inputs (again, remember that the four binned variables replace their original counterparts). We set the degree of interaction to 2. The summary of the MARS model is below: 

```{r}
# MARS
model.mars <- earth(formula, data=train, degree=2, glm=list(family=binomial))
# Summary
summary.mars <- summary(model.mars)
summary.mars

# AIC
aic.mars <- round(summary.mars$glm.stats[6], 3)
# Predicted probabilities of Bad 
probs.mars <- predict(model.mars, newdata=test, type='response')
```

We see that MARS automatically selects variables and the knots of the hinge functions, and it selected 17 of 33 terms and 11 of 59 predictors. The AIC of the MARS model is 2877, which is lower than that of the logistic regression model (2973.4). That is, MARS performed slightly better than the logistic.

Next, we move on to model evaluation (KS, ROC, gains table, and lift).

```{r, fig.height=4, fig.width=9}
#### ROC and KS (MARS)
# ROC
roc.mars.train <- rocit(score=as.vector(model.mars$fitted.values), class=train$Bad, negref=0)  # Training
roc.mars.test <- rocit(score=as.vector(probs.mars), class=test$Bad, negref=0)  # Validation

# AUC
auc.mars.train <- round(roc.mars.train$AUC, 4)  # Training
auc.mars.test <- round(roc.mars.test$AUC, 4)  # Validation

par(mfrow=c(1,2))
# KS plots
ksplot.mars.train <- ksplot(roc.mars.train)  # Training
ksplot.mars.test <- ksplot(roc.mars.test)  # Validation

# KS statistics
ks.mars.train <- round(ksplot.mars.train$`KS stat`, 4)  # Training
ks.mars.test <- round(ksplot.mars.test$`KS stat`, 4)  # Validation
```
\begin{center}
Figure 8: KS plots of the training (left) and validation sets (right) for MARS.
\end{center}

**Figure 8** shows the KS plots of the training and validation sets for MARS.

```{r}
#### ROC and KS (MARS)
# ROC curves
plot(roc.mars.train, col=c(1,'gray50'), legend=FALSE, YIndex=FALSE)
lines(roc.mars.test$TPR~roc.mars.test$FPR, col='#D55E00', lwd=2)
legend('bottomright', col=c(1,'#D55E00'), c(paste0('Training: AUC = ', auc.mars.train, ', KS = ', ks.mars.train), 
                                            paste0('Validation: AUC = ', auc.mars.test, ', KS = ', ks.mars.test)), lwd=2)
title(main='MARS ROC Curves')
```
\begin{center}
Figure 9: ROC curves of the training and validation sets for MARS.
\end{center}

**Figure 9** shows the ROC curves of the training and validation sets for MARS. The training and validation AUC's are 0.717 and 0.686, respectively. The training and validation KS statistics are 0.313 and 0.286, respectively.

```{r, fig.height=5, fig.width=10}
#### Gains table (logistic)
# Gains table
gtable.mars.training <- gainstable(score=as.vector(model.mars$fitted.values),  
                                   class=train$Bad, negref=0, ngroup=10)  # Training  
#kable(as.data.frame(gtable.mars.training[1:11]), digits=2, caption='Gains Table (Training)')
gtable.mars.test <- gainstable(score=as.vector(probs.mars),  
                               class=test$Bad, negref=0, ngroup=10)  # Validation   
kable(as.data.frame(gtable.mars.test[1:11]), digits=2, caption='MARS Gains Table (Validation)')

par(mfrow=c(1,2))
# Lift
plot(gtable.mars.training)  # Training
title('MARS Lift (Training)')
plot(gtable.mars.test)  # Validation
title('MARS Lift (Validation)')
```
\begin{center}
Figure 10: Lift and cumulative lift of the training (left) and validation sets (right) for MARS.
\end{center}

**Table 2** shows the gains table of the validation set, and **Figure 10** shows the lift and cumulative lift of the training and validation sets for MARS.

## 4.3 Good Customer Score
Now, we compare our model to the *Good Customer Score*. This score can be considered as a model and is simply a probability or log-odds transformed into points. Since rank order is retained, we can calculate or plot the ROC/AUC, KS, gains table, and lift for *Good Customer Score*. 

```{r}
# Remove 0's from Good Customer Score
gcs.data2 <- gcs.data[gcs.data$Good.Customer.Score != 0, ]
# Remove NA's from Good Customer Score
gcs.data2 <- gcs.data2[complete.cases(gcs.data2), ]
```

```{r}
#### ROC and KS (Good Customer Score)
# ROC
roc.gcs <- rocit(score=gcs.data2$Good.Customer.Score, class=gcs.data2$Bad, negref=1) 
# AUC
auc.gcs <- round(roc.gcs$AUC, 4) 

# KS plot
ksplot.gcs <- ksplot(roc.gcs) 
# KS statistic
ks.gcs <- round(ksplot.gcs$`KS stat`, 4)  # Training
```
\begin{center}
Figure 11: KS plot for Good Customer Score.
\end{center}

```{r}
#### ROC and KS (Good Customer Score)
# ROC curve
plot(roc.gcs, legend=FALSE, YIndex=FALSE)
legend('bottomright', c(paste0('AUC = ', auc.gcs, ', KS = ', ks.gcs)))
title(main='Good Customer Score ROC Curve')
```
\begin{center}
Figure 12: ROC curve for Good Customer Score.
\end{center}

```{r, fig.height=4, fig.width=5}
#### Gains table (Good Customer Score)
quantile <- quantile(gcs.data2$Good.Customer.Score, probs=seq(0.1, 1, 0.1))
# Gains table
gtable.gcs <- gainstable(score=gcs.data2$Good.Customer.Score, class=gcs.data2$Bad, negref=1, ngroup=10)  
kable(as.data.frame(gtable.gcs[1:11]), digits=2, caption='Good Customer Score Gains Table')

# Lift
plot(gtable.gcs, legend=FALSE)
title('Good Customer Score Lift')
legend("bottomright", c("Lift", "Cumulative Lift"), col=c("#BEBEBE", "#26484F"), lwd=2, lty=1, pch=15:16)
```
\begin{center}
Figure 13: Lift and cumulative lift for Good Customer Score.
\end{center}

**Table 3** shows the gains table for *Good Customer Score*. **Figures 11-13** shows the KS plot, ROC curve, and lift and cumulative lift for *Good Customer Score*. The AUC is 0.683, and the KS statistic is 0.278. A caveat here is that the **ROCit** package sorts the *Good Customer Score* by descending order, which means the good customers tend be in the top buckets. In contrast, for the logistic and MARS models, the predicted probabilities of being bad is sorted by descending order, which means the bad customers tend to be in the top buckets. **See the powerpoint for the corrected Good Customer Score gains table and lift.**

\newpage

## 4.4 Model Comparison
**Table 4** compares the AUC and KS among the logistic, MARS, and *Good Customer Score* models. We see that all three models performed similarly; in fact, MARS was able to slightly outperform *Good Customer Score*.

```{r}
# Model performance measures
stats.logistic <- c(auc.logistic.test, ks.logistic.test)
stats.mars <- c(auc.mars.test, ks.mars.test)
stats.gcs <- c(auc.gcs, ks.gcs)

# Model comparison table
dt <- rbind('Logistic (Validation)'=stats.logistic, 'MARS (Validation)'=stats.mars, 'Good Customer Score'=stats.gcs)
kable(dt, col.names=c('AUC','KS'), caption='Model Comparison')
```

# 5. Are We Making Money?
Finally, we use all rows of each customer in the model dataset to calculate *Net Profit*. This is a profit for a good customer and a loss for a bad customer. It is calculated as:

- For good customers (*Bad* = 0), sum up *Net Payments During Cycle* for all rows of each customer
- For bad customers (*Bad* = 1), take the *Ending Balance* from the last row of each customer. If the *Ending Balance* is 0 in the last row, take the *Ending Balance* from the second to last row.

```{r}
# Remove duplicate rows
x <- x %>% distinct(DebtDimID, Row.Num, .keep_all=TRUE)
# Extract first row of each customer
tmp <- x[!duplicated(x$DebtDimID),]
# Remove customers with Row Num !=1 in first row
tmp <- tmp[tmp$Row.Num !=1, ]
x <- x[!x$DebtDimID %in% tmp$DebtDimID, ]

# Subset into good and bad customers
good.customers <- subset(x, Bad==0)
bad.customers <- subset(x, Bad==1)

#### Profit per good customer
# Create data frame of ID and net profit for good customers
profit.good <- aggregate(list(Net.Profit=good.customers$Net.Payments.During.Cycle), by=list(DebtDimID=good.customers$DebtDimID), FUN=sum)
# Total profit per good customer
total.profit <- format(sum(profit.good$Net.Profit), big.mark=',', trim=TRUE)
#cat('Total profit from good customers: $', total.profit, '\n', sep='')
# Profit per good customer
profit.per.good <- format(round(mean(profit.good$Net.Profit), 2), big.mark=',', trim=TRUE)
#cat('Profit per good customer: $', profit.per.good, '\n', sep='')

#### Loss per bad customer
# Extract last and second to last rows of each bad customer
tmp <- bad.customers %>%
  group_by(DebtDimID) %>%
  arrange(Row.Num) %>%
  slice(c(n()-1, n()))
# Remove rows with Ending Balance = 0
tmp <- tmp[tmp$Ending.Balance !=0, ]
# Extract last row of each bad customer again
tmp <- tmp %>%
  group_by(DebtDimID) %>%
  arrange(Row.Num) %>%
  slice(n())
# Create data frame of ID and net loss for bad customers
loss.bad <- data.frame(DebtDimID=tmp$DebtDimID, Net.Loss=tmp$Ending.Balance)
# Total loss per bad customer
total.loss <- format(sum(loss.bad$Net.Loss), big.mark=',', trim=TRUE)
#cat('Total loss from bad customers: $', total.loss, '\n', sep='')
# Loss per bad customer
loss.per.bad <- format(round(mean(loss.bad$Net.Loss), 2), big.mark=',', trim=TRUE)
#cat('Loss per bad customer: $', loss.per.bad, sep='')
```

We find that for good customers, we earn a total profit of $3,125,741 and a profit per customer of \$616.27. For bad customers, we suffer a total loss of \$300,766.9 and a loss per customer of \$399.96. This gives us a total net profit of \$2,824,974. With this information, we can calculate the profitability in the logistic and MARS gains tables. **See the powerpoint for enhanced versions of the logistic and MARS gains tables.** We see that we are indeed making money.

# 6. Conclusion
The logistic and MARS models both provide decent separation of good and bad customers. Both models perform on par with the *Good Customer Score*, with the MARS model having the slight edge. We also see from the calculated profits in the logistic and MARS gains tables that we are indeed making money. A recommeded course of action based on these gains tables is to give incentives in the form of credit line increases or annual fee waivers to the good customers in the bottom buckets. This willl encourage them to use their credit cards more, thereby increasing our profit. 

